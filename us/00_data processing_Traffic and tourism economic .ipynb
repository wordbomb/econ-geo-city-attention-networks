{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yjf/miniconda3/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "import pandas as pd\n",
    "from shapely.ops import transform\n",
    "from pyproj import Transformer\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been exported to data/USA_transportation.csv.\n"
     ]
    }
   ],
   "source": [
    "with open('input_data/state_info.json', 'r') as f:\n",
    "    state_fips_to_name = json.load(f)\n",
    "\n",
    "with open('input_data/county_boundary.json', 'r') as file:\n",
    "    county_boundary_data = json.load(file)\n",
    "\n",
    "filtered_county_boundary_data = [feature for feature in county_boundary_data['features'] if feature['properties']['STATEFP'] != '09']\n",
    "\n",
    "with open('input_data/gadm41_USA_2.json', 'r') as file:\n",
    "    ct_boundary_data = json.load(file)\n",
    "\n",
    "def find_state_fips(state_name, state_fips_to_name):\n",
    "    for fips, info in state_fips_to_name.items():\n",
    "        if info['name'].lower().replace(\" \", \"\") == state_name.lower().replace(\" \", \"\"):\n",
    "            return fips\n",
    "    return None\n",
    "\n",
    "\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3097\", always_xy=True)\n",
    "  \n",
    "county_data = []\n",
    "\n",
    "for feature in filtered_county_boundary_data:\n",
    "    state_fips = feature['properties']['STATEFP']\n",
    "    try:\n",
    "        state_name = state_fips_to_name[state_fips][\"name\"]\n",
    "        state_abbr = state_fips_to_name[state_fips][\"abbreviation\"]\n",
    "    except KeyError:\n",
    "        continue\n",
    "    county_fips = feature['properties']['COUNTYFP']\n",
    "    county_name = feature['properties']['NAMELSAD']\n",
    "    \n",
    "    boundary_coords = feature['geometry']['coordinates']\n",
    "    \n",
    "    if feature['geometry']['type'] == 'MultiPolygon':\n",
    "        polygons = []\n",
    "        for polygon_coords in boundary_coords:\n",
    "            exterior_coords = polygon_coords[0]\n",
    "            interior_coords = [coords for coords in polygon_coords[1:]]\n",
    "            polygons.append(Polygon(exterior_coords, interior_coords))\n",
    "        \n",
    "        boundary = MultiPolygon(polygons)\n",
    "\n",
    "    centroid = boundary.centroid\n",
    "    latitude = centroid.y\n",
    "    longitude = centroid.x\n",
    "    projected_boundary = transform(transformer.transform, boundary)\n",
    "    \n",
    "        \n",
    "    county_data.append({\n",
    "        'State Name': state_name,\n",
    "        'State Abbr': state_abbr,\n",
    "        'State Fips': state_fips,\n",
    "        'County Name': county_name,\n",
    "        'Boundary': boundary,\n",
    "        'Latitude': latitude,\n",
    "        'Longitude': longitude,\n",
    "        'Area':projected_boundary.area/ 1e6\n",
    "    })\n",
    "\n",
    "for feature in ct_boundary_data['features']:\n",
    "    state_name = feature['properties']['NAME_1']\n",
    "    \n",
    "    if state_name.lower() == \"connecticut\":\n",
    "        state_fips = find_state_fips(state_name, state_fips_to_name)\n",
    "        state_abbr = state_fips_to_name[state_fips][\"abbreviation\"]\n",
    "        county_name = feature['properties']['NAME_2']\n",
    "        \n",
    "        boundary_coords = feature['geometry']['coordinates']\n",
    "        if feature['geometry']['type'] == 'MultiPolygon':\n",
    "            polygons = []\n",
    "            for polygon_coords in boundary_coords:\n",
    "                exterior_coords = polygon_coords[0] \n",
    "                interior_coords = [coords for coords in polygon_coords[1:]]\n",
    "                polygons.append(Polygon(exterior_coords, interior_coords))\n",
    "            \n",
    "            boundary = MultiPolygon(polygons)\n",
    "            \n",
    "        centroid = boundary.centroid\n",
    "        latitude = centroid.y\n",
    "        longitude = centroid.x\n",
    "        projected_boundary = transform(transformer.transform, boundary)\n",
    "   \n",
    "        county_data.append({\n",
    "            'State Name': state_name,\n",
    "            'State Abbr': state_abbr,\n",
    "            'State Fips': state_fips,\n",
    "            'County Name': county_name,\n",
    "            'Boundary': boundary,\n",
    "            'Latitude': latitude,\n",
    "            'Longitude': longitude,\n",
    "            'Area':projected_boundary.area/ 1e6\n",
    "        })\n",
    "\n",
    "suffixes_to_remove = ['county', 'census area', 'city and borough', 'borough', 'municipality', 'parish']\n",
    "def remove_suffix(name, suffixes):\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, suffixes)) + r')\\b'\n",
    "    return re.sub(pattern, '', name).strip()\n",
    "\n",
    "\n",
    "\n",
    "county_data=pd.DataFrame(county_data)\n",
    "county_data['County Name_clean'] = county_data['County Name'].str.lower().str.strip()\n",
    "county_data['County Name_clean'] = county_data['County Name_clean'].apply(remove_suffix, suffixes=suffixes_to_remove)\n",
    "\n",
    "\n",
    "def match_county(row):\n",
    "    state_abbr = row['state_abbr']\n",
    "    geo_name = row['GeoName_clean']\n",
    "    possible_counties = county_data[county_data['State Abbr'] == state_abbr]['County Name_clean'].tolist()\n",
    "\n",
    "    match = process.extractOne(geo_name, possible_counties, score_cutoff=80)\n",
    "    if match:\n",
    "        return match[0] \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "economy_df = pd.read_excel('input_data/usa_economy.xlsx')\n",
    "\n",
    "economy_df['Matched County Name'] = None\n",
    "economy_df['GeoName'] = economy_df['GeoName'].str.replace('(Independent City)', 'City')\n",
    "economy_df['state_abbr'] = economy_df['state_abbr'].str.strip().str.replace('*', '', regex=False)\n",
    "economy_df['GeoName_clean'] = economy_df['GeoName'].str.lower().str.strip()\n",
    "economy_df['GeoName_clean'] = economy_df['GeoName_clean'].apply(remove_suffix, suffixes=suffixes_to_remove)\n",
    "\n",
    "economy_df['Matched County Name'] = economy_df.apply(match_county, axis=1)\n",
    "\n",
    "adm2_data_df = pd.merge(\n",
    "    economy_df,\n",
    "    county_data[['State Abbr', 'County Name_clean', 'Latitude', 'Longitude', 'Area']],\n",
    "    left_on=['state_abbr', 'Matched County Name'],\n",
    "    right_on=['State Abbr', 'County Name_clean'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "adm2_data_df = pd.DataFrame(adm2_data_df )\n",
    "adm2_data_df[['id', 'Latitude', 'Longitude', 'Area']].to_csv('data/usa_adm2_locations_area.csv', index=False)\n",
    "\n",
    "file_path = 'input_data/usa-airports.csv'\n",
    "airport_data = pd.read_csv(file_path)\n",
    "with open('input_data/usa_ferry_terminals.geojson', 'r',encoding='utf-8') as file:\n",
    "    ferry_data = json.load(file)\n",
    "with open('input_data/usa_railway_station.geojson', 'r',encoding='utf-8') as file:\n",
    "    train_data = json.load(file)\n",
    "    \n",
    "train_data['features'] = [\n",
    "    station for station in train_data['features']\n",
    "    if station['properties'].get('station') not in ['subway', 'light_rail']\n",
    "]\n",
    "\n",
    "airport_data = airport_data[airport_data['type'].isin(['medium_airport', 'large_airport'])]\n",
    "\n",
    "def find_city_by_coordinates(lat, lon):\n",
    "    point = Point(lon, lat)\n",
    "    for _, row in county_data.iterrows():\n",
    "        boundary = row['Boundary']\n",
    "        if boundary.contains(point):\n",
    "            return row['State Name'], row['State Abbr'], row['County Name']\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "city_status_dict = {\n",
    "    (row['State Name'].lower(), row['State Abbr'], row['County Name'].lower()): {'Has Airport': 0, 'Has Ferry Terminal': 0, 'Has Train Station': 0}\n",
    "    for _, row in county_data.iterrows()\n",
    "}\n",
    "\n",
    "\n",
    "for _, row in airport_data.iterrows():\n",
    "    latitude = row['latitude_deg']\n",
    "    longitude = row['longitude_deg']\n",
    "    state_name, state_abbr, city_name = find_city_by_coordinates(latitude, longitude)\n",
    "    \n",
    "    if state_name and city_name:\n",
    "        key = (state_name.lower(), state_abbr, city_name.lower())\n",
    "        if key in city_status_dict:\n",
    "            city_status_dict[key]['Has Airport'] = 1\n",
    "\n",
    "for feature in ferry_data['features']:\n",
    "    latitude = feature['geometry']['coordinates'][1]\n",
    "    longitude = feature['geometry']['coordinates'][0]\n",
    "    \n",
    "    state_name, state_abbr, city_name = find_city_by_coordinates(latitude, longitude)\n",
    "    \n",
    "    if state_name and city_name:\n",
    "        key = (state_name.lower(), state_abbr, city_name.lower())\n",
    "        if key in city_status_dict:\n",
    "            city_status_dict[key]['Has Ferry Terminal'] = 1\n",
    "\n",
    "for feature in train_data['features']:\n",
    "    latitude = feature['geometry']['coordinates'][1]\n",
    "    longitude = feature['geometry']['coordinates'][0]\n",
    "    \n",
    "    state_name, state_abbr, city_name = find_city_by_coordinates(latitude, longitude)\n",
    "    \n",
    "    if state_name and city_name:\n",
    "        key = (state_name.lower(), state_abbr, city_name.lower())\n",
    "        if key in city_status_dict:\n",
    "            city_status_dict[key]['Has Train Station'] = 1\n",
    "            \n",
    "county_status_df = pd.DataFrame.from_dict(city_status_dict, orient='index').reset_index()\n",
    "county_status_df.columns = ['State Name','State Abbr', 'County Name', 'Has Airport', 'Has Ferry Terminal', 'Has Train Station']\n",
    "\n",
    "county_status_df['State Name'] = county_status_df['State Name'].str.title()\n",
    "county_status_df['County Name'] = county_status_df['County Name'].str.title()\n",
    "\n",
    "output_file_path = 'data/USA_transportation.csv'\n",
    "county_status_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been exported to {output_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3114/3114 [06:35<00:00,  7.87it/s] \n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "from geopy.distance import geodesic \n",
    "from tqdm import tqdm \n",
    "import pandas as pd \n",
    "\n",
    "adm2_data = pd.read_csv('data/usa_adm2_locations_area.csv')\n",
    "\n",
    "adm2_data = adm2_data.to_dict(orient='records')\n",
    "\n",
    "distances = {}\n",
    "\n",
    "for i, place1 in tqdm(enumerate(adm2_data), total=len(adm2_data)):\n",
    "    place1_key = f\"{place1['id']}\"\n",
    "    distances[place1_key] = {}\n",
    "    for j, place2 in enumerate(adm2_data[i+1:]):\n",
    "        place2_key = f\"{place2['id']}\"\n",
    "        dist = geodesic((place1['Latitude'], place1['Longitude']),\n",
    "                        (place2['Latitude'], place2['Longitude'])).km\n",
    "        distances[place1_key][place2_key] = dist\n",
    "        \n",
    "with open('data/usa_adm2_distances.txt', 'w') as f:\n",
    "    for place1, dist_dict in distances.items():\n",
    "        for place2, dist in dist_dict.items():\n",
    "            f.write(f\"{place1}\\t{place2}\\t{dist:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "economy_df = pd.read_excel('input_data/usa_economy.xlsx')\n",
    "county_status_df = pd.read_csv('data/USA_transportation.csv')\n",
    "\n",
    "economy_df['GeoName'] = economy_df['GeoName'].str.replace('(Independent City)', 'City')\n",
    "economy_df['us-popu'] = economy_df['us-popu'].replace(',', '', regex=True).astype(float)\n",
    "economy_df['state_abbr'] = economy_df['state_abbr'].str.strip().str.replace('*', '', regex=False)\n",
    "\n",
    "county_status_df['State Abbr'] = county_status_df['State Abbr'].str.strip().str.replace('*', '', regex=False)\n",
    "\n",
    "economy_df['GeoName_clean'] = economy_df['GeoName'].str.lower().str.strip()\n",
    "county_status_df['County Name_clean'] = county_status_df['County Name'].str.lower().str.strip()\n",
    "\n",
    "suffixes_to_remove = ['county', 'census area', 'city and borough', 'borough', 'municipality', 'parish']\n",
    "\n",
    "def remove_suffix(name, suffixes):\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, suffixes)) + r')\\b'\n",
    "    return re.sub(pattern, '', name).strip()\n",
    "\n",
    "economy_df['GeoName_clean'] = economy_df['GeoName_clean'].apply(remove_suffix, suffixes=suffixes_to_remove)\n",
    "county_status_df['County Name_clean'] = county_status_df['County Name_clean'].apply(remove_suffix, suffixes=suffixes_to_remove)\n",
    "\n",
    "\n",
    "economy_df['Matched County Name'] = None\n",
    "\n",
    "def match_county(row):\n",
    "    state_abbr = row['state_abbr']\n",
    "    geo_name = row['GeoName_clean']\n",
    "    \n",
    "    possible_counties = county_status_df[county_status_df['State Abbr'] == state_abbr]['County Name_clean'].tolist()\n",
    "    \n",
    "    match = process.extractOne(geo_name, possible_counties, score_cutoff=80)\n",
    "    \n",
    "    if match:\n",
    "        return match[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "economy_df['Matched County Name'] = economy_df.apply(match_county, axis=1)\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    economy_df,\n",
    "    county_status_df[['State Name','State Abbr', 'County Name', 'County Name_clean', 'Has Airport', 'Has Ferry Terminal', 'Has Train Station']],\n",
    "    left_on=['state_abbr', 'Matched County Name'],\n",
    "    right_on=['State Abbr', 'County Name_clean'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_columns = ['GeoName','State Name', 'state_abbr', 'County Name', 'Has Airport', 'Has Ferry Terminal', 'Has Train Station'] + economy_df.columns.tolist()\n",
    "\n",
    "merged_df.to_excel('data/usa_transportation_economy.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "usa_transportation_economy_df = pd.read_excel('data/usa_transportation_economy.xlsx')\n",
    "usa_attractions_df = pd.read_excel('input_data/usa_attractions.xlsx')\n",
    "\n",
    "score_columns = ['5', '4', '3', '2', '1']\n",
    "for col in score_columns:\n",
    "    usa_attractions_df[col] = pd.to_numeric(usa_attractions_df[col], errors='coerce')\n",
    "\n",
    "grouped_attractions = usa_attractions_df.groupby(['Matched_State', 'Matched_Location']).agg(\n",
    "    total_attractions=('Matched_Location', 'size'),\n",
    "    total_reviews=('reviews', 'sum'),\n",
    "    five_score=('5', 'sum'),\n",
    "    four_score=('4', 'sum'),\n",
    "    three_score=('3', 'sum'),\n",
    "    two_score=('2', 'sum'),\n",
    "    one_score=('1', 'sum'),\n",
    ").reset_index()\n",
    "\n",
    "merged_df = pd.merge(usa_transportation_economy_df, grouped_attractions, left_on=['State Name', 'County Name'],\n",
    "                     right_on=['Matched_State', 'Matched_Location'], how='left')\n",
    "\n",
    "merged_df.drop(['Matched_State', 'Matched_Location', 'GeoName_clean',\t'Matched County Name', 'State Name' ,'State Abbr',\t'County Name' , 'County Name_clean'\n",
    "], axis=1, inplace=True)\n",
    "\n",
    "merged_df.to_excel('data/usa_transportation_economy_attractions.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "adm2_data_locations_area=pd.read_csv('data/usa_adm2_locations_area.csv')\n",
    "adm2_area = dict(zip(adm2_data_locations_area['id'], adm2_data_locations_area['Area']))\n",
    "\n",
    "adm2_transportation_economy_attractions=pd.read_excel('data/usa_transportation_economy_attractions.xlsx')\n",
    "adm2_transportation_economy_attractions[['total_attractions', 'total_reviews', 'five_score', 'four_score', 'three_score', 'two_score', 'one_score']] = adm2_transportation_economy_attractions[['total_attractions', 'total_reviews', 'five_score', 'four_score', 'three_score', 'two_score', 'one_score']].fillna(0)\n",
    "adm2_transportation_economy_attractions['tourism_quality'] = (\n",
    "    10 * adm2_transportation_economy_attractions['five_score'] +\n",
    "    8 * adm2_transportation_economy_attractions['four_score'] +\n",
    "    4 * adm2_transportation_economy_attractions['three_score'] +\n",
    "    2 * adm2_transportation_economy_attractions['two_score'] +\n",
    "    1 * adm2_transportation_economy_attractions['one_score']\n",
    ")\n",
    "\n",
    "adm2_transportation_economy_attractions['us-popu'] = adm2_transportation_economy_attractions['us-popu'].replace(',', '', regex=True).astype(float)\n",
    "adm2_transportation_economy_attractions['us-gdp'] = adm2_transportation_economy_attractions['us-gdp'].replace(',', '', regex=True).astype(float)\n",
    "\n",
    "adm2_population = dict(zip(adm2_transportation_economy_attractions['id'], adm2_transportation_economy_attractions['us-popu']))\n",
    "adm2_income = dict(zip(adm2_transportation_economy_attractions['id'], adm2_transportation_economy_attractions['us-gdp']))\n",
    "adm2_tourism_quality = dict(zip(adm2_transportation_economy_attractions['id'], adm2_transportation_economy_attractions['tourism_quality']))\n",
    "\n",
    "        \n",
    "adm2_distances = {}\n",
    "with open('data/usa_adm2_distances.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        place1, place2, dist = line.strip().split('\\t')\n",
    "        place1 = int(place1)\n",
    "        place2 = int(place2)\n",
    "        dist = float(dist)\n",
    "        if place1 not in adm2_distances:\n",
    "            adm2_distances[place1] = {}\n",
    "        if place2 not in adm2_distances:\n",
    "            adm2_distances[place2] = {}\n",
    "        adm2_distances[place1][place2] = dist\n",
    "        adm2_distances[place2][place1] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24005 24510 0.0\n",
      "24510 24005 0.0\n",
      "29189 29510 0.0\n",
      "29510 29189 0.0\n",
      "51159 51760 0.0\n",
      "51650 51949 0.0\n",
      "51760 51159 0.0\n",
      "51770 51944 0.0\n",
      "51944 51770 0.0\n",
      "51949 51650 0.0\n"
     ]
    }
   ],
   "source": [
    "with open('data/usa_population_attraction_scores.txt', 'w') as f:\n",
    "    for place1, dist_dict in adm2_distances.items():\n",
    "        if place1 in adm2_population:\n",
    "            pop1 = adm2_population[place1]\n",
    "            total_score = 0\n",
    "            for place2, dist in dist_dict.items():\n",
    "                if place2 in adm2_population and dist > 0:\n",
    "                    pop2 = adm2_population[place2]\n",
    "                    score = (pop1 * pop2) / dist\n",
    "                    total_score += score\n",
    "            f.write(f\"{place1}\\t{total_score:.2f}\\n\")\n",
    "            \n",
    "with open('data/usa_tourism_attraction_scores.txt', 'w') as f:\n",
    "    for place1, dist_dict in adm2_distances.items():\n",
    "        if place1 in adm2_tourism_quality:\n",
    "            pop1 = adm2_tourism_quality[place1]\n",
    "            total_score = 0\n",
    "            for place2, dist in dist_dict.items():\n",
    "                if place2 in adm2_tourism_quality and dist > 0:\n",
    "                    pop2 = adm2_tourism_quality[place2]\n",
    "                    score = (pop1 * pop2) / dist\n",
    "                    total_score += score\n",
    "            f.write(f\"{place1}\\t{total_score:.2f}\\n\")\n",
    "            \n",
    "def self_potential(GDP_i, area_i):\n",
    "    return GDP_i / ((2 / 3) * np.sqrt(area_i / np.pi))\n",
    "\n",
    "\n",
    "HMP = {}\n",
    "for place1 in adm2_income:\n",
    "    GDP_i = adm2_income[place1]\n",
    "    area_i = adm2_area[place1]\n",
    "\n",
    "    potential_sum = 0\n",
    "    for place2, dist in adm2_distances.get(place1, {}).items():\n",
    "        if place1 != place2:\n",
    "            try:\n",
    "                GDP_j = adm2_income[place2]\n",
    "                potential_sum += GDP_j / dist\n",
    "            except:\n",
    "                print(place1,place2,dist)\n",
    "            \n",
    "    \n",
    "    self_term = self_potential(GDP_i, area_i)\n",
    "    \n",
    "    HMP[place1] = potential_sum + self_term\n",
    "\n",
    "HMP_df = pd.DataFrame(list(HMP.items()))\n",
    "HMP_df.to_csv('data/usa_harris_market_potential.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_attraction_scores = pd.read_csv('data/usa_population_attraction_scores.txt', sep='\\t', header=None, names=['id', 'population_attraction_score'])\n",
    "tourism_attraction_scores = pd.read_csv('data/usa_tourism_attraction_scores.txt', sep='\\t', header=None, names=['id', 'tourism_attraction_scores'])\n",
    "harris_market_potential = pd.read_csv('data/usa_harris_market_potential.txt', sep='\\t', header=None, names=['id', 'harris_market_potential'])\n",
    "\n",
    "merged_data = pd.merge(adm2_transportation_economy_attractions, population_attraction_scores, on='id', how='left')\n",
    "merged_data = pd.merge(merged_data, tourism_attraction_scores, on='id', how='left')\n",
    "merged_data = pd.merge(merged_data, harris_market_potential , on='id', how='left')\n",
    "\n",
    "merged_data = pd.merge(merged_data, adm2_data_locations_area , on='id', how='left')\n",
    "merged_data.to_csv('data/final_scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
